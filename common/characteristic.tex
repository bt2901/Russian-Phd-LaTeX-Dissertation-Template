
\textbf{Актуальность темы исследования.} 
Тематическое моделирование --- это обширное направление исследований в области автоматической обработки текстов. Тематическая модель коллекции текстовых документов определяет, к каким темам относится каждый документ и из каких слов состоит каждая тема. В отличие от обычных методов кластеризации, тематическая модель может относить документ не к одному кластеру-теме, а к нескольким, то есть  она производит <<мягкую кластеризацию>>, причём не только документов, но и слов. 

Обычно тематические модели относят к методам машинного обучения <<без учителя>>, поскольку они не требуют размеченных обучающих выборок. Это позволяет использовать тематическое моделирование в тех случаях, когда никаких дополнительных данных, кроме собственно текстовой коллекции, не имеется, например, для информационного поиска в больших текстовых массивах, для анализа специализированных текстов или текстов на редких языках, для анализа больших массивов тексто-подобных данных, таких, как программный код, тексты песен, банковские транзакции, географические данные, музыкальные произведения.

Результатом вероятностного тематического моделирования является конечное множество \textit{тем}, каждая из которых описывается вероятностным распределением на множестве слов. Важным свойством темы является её интерпретируемость. Слова, имеющие большую вероятность в данной теме, должны относиться к одной предметной области и быть семантически связанными. Тема считается интерпретируемой, если, рассматривая наиболее частотные слова темы, эксперт может сказать, о чём эта тема, и дать ей определённое название~\cite{rtl}. Если все темы (или почти все) интерпретируемые, то о такой модели говорят, что она в целом является интерпретируемой. В таком случае модель может быть полезна для понимания тематической структуры коллекции. Интерпретируемость является трудно формализуемой характеристикой, поэтому существуют различные методики её количественного оценивания, как связанные с экспертными оценками, так и вычисляемые полностью автоматически \cite{newman2010automatic}.  

Развитие вероятностного тематического моделирования началось с работы Т.Хофманна \cite{hofmann1999}, в которой была предложена модель вероятностного латентного семантического анализа (Probabilistic Latent Semantic Analysis, PLSA). Построение тематической модели является некорректно поставленной задачей стохастического матричного разложения, которая имеет бесконечное множество решения. Для доопределения постановки задачи и выбора наиболее подходящего решения необходимо вводить дополнительные ограничения на модель. Следующей важной вехой стала модель латентного размещения Дирихле (Latent Dirichlet Allocation, LDA) \cite{blei2003latent}, основанная на байесовской регуляризации искомых дискретных распределений с помощью априорных распределений Дирихле. В последующие годы на основе PLSA и LDA были разработаны сотни специализированных моделей, отличающихся способами регуляризации, структурой исходных данных и матричного разложения \cite{daud10knowledge,blei2012,fntir2017applications}. 

Аддитивная регуляризация тематических моделей (ARTM) позволяет комбинировать регуляризаторы для создания моделей с заданными свойствами \cite{voron14dan-eng,voron15mlj}. Это многокритериальный подход, основанный на оптимизации взвешенной суммы основного критерия (логарифма правдоподобия) и некоторого количества дополнительных критериев-регуляризаторов. Многокритериальный подход является ответом на практическую потребность строить модели, обладающие целым рядом необходимых свойств одновременно \cite{kochedykov2017fast}. 
Соответственно, в каждой конкретной задаче тематического моделирования может быть много не только оптимизационных критериев, но и метрик качества, с помощью которых валидируется (оценивается) построенная модель. В частности, в \cite{voron15mlj,voron15mlj} было показано, что комбинирование регуляризаторов сглаживания, разреживания, декоррелирования и отбора тем позволяет одновременно улучшить несколько метрик качества (разреженность, различность и интерпретируемость тем) без заметного ухудшения основного критерия правдоподобия (или перплексии) модели. Тематические модели для разведочного информационного поиска, в дополнение к этим свойствам, должны быть также мультимодальными (учитывать не только слова, но и биграммы, теги, категории, авторство документов) и иерархическими (разделять крупные темы на более мелкие подтемы) \cite{ianina2019regularized}. 

На основе теории аддитивной регуляризации тематических моделей
была разработана библиотека тематического моделирования с открытым кодом BigARTM \cite{vorontsov2015bigartm,frei2016parallel}. 
Свойство аддитивности регуляризаторов позволило реализовать в BigARTM модульный подход, когда пользователь выбирает из библиотеки нужный ему набор регуляризаторов для построения модели с требуемыми свойствами. 
Возможность конструирования новых композитных моделей из <<готовых блоков>> существенно отличает BigARTM от других средств тематического моделирования, основанных на теории байесовского обучения, в которой каждая новая модель требует проведения уникальных математических выкладок (байесовского вывода) и, как следствие, разработки нового программного кода. 

Несмотря на модульность, гибкость, масштабируемость и высокую производительность BigARTM \cite{kochedykov2017fast}, библиотека создаёт ряд трудностей при её практическом применении. Пользователь должен хорошо разбираться в теории ARTM, чтобы грамотно выбрать стратегию регуляризации, то есть последовательность включения регуляризаторов, затем подобрать гиперпараметры тематической модели~--- число тем и коэффициенты регуляризации для каждого регуляризатора, а также экзогенные параметры внутри регуляризаторов, если таковые имеются. Эта работа связана с проведением серий вычислительных экспериментов, которые требуют тщательного планирования, журнализации, валидации, визуализации и критического осмысления промежуточных результатов. Таким образом, BigARTM перекладывает на пользователя значительный объём работы, требующей пристального внимания и высокой квалификации. 

Актуальной задачей является создание технических средств для автоматизации экспериментов по построению аддитивно регуляризованных тематических моделей, их валидации и выбора лучшей модели по заданной совокупности метрик качества. 

\textbf{Степень разработанности темы исследования.}
Тематическое моделирование является полезным инструментом в цифровых гуманитарных исследованиях (digital humanities) \cite{grimmer2013text,paakkonen2020humanistic}. Однако процессы построения, валидации и выбора тематических моделей практически не алгоритмизированы \cite{paakkonen2020humanistic}. Большое прикладное значение имеет разработка новых методов визуализации, автоматической валидации и выбора моделей \cite{dh_sea}.

Также исследователи сталкиваются с неустойчивостью \cite{mantyla2018measuring} и неинтерпретируемостью тем \cite{boydcare}. Известно, что настройка гиперпараметров модели может повысить её устойчивость \cite{agrawal2018wrong}, однако на практике она выполняется редко, и для неё нет единой принятой методологии  \cite{agrawal2018wrong,chen2016survey}.

Настройка гиперпараметров может помочь и с интерпретируемостью тем, особенно в рамках подхода ARTM. Известные регуляризаторы, такие как регуляризатор декоррелирования, способствуют повышению различности и интерпретируемости тем \cite{popov_hier}; также можно использовать  регуляризатор, напрямую оптимизирующий заданный критерий, как это было сделано в \cite{4keys} для критерия средней когерентности тем.

К сожалению, интерпретируемости трудно дать формальное определение. Попытки определить плохие темы через расстояние до известных <<мусорных>> тем или через низкие значения когерентности дают лишь срез проблематичных тем и имеют ограниченную область применимости \cite{boydcare}. Системный подход к измерению интерпретируемости предполагает оценивание каждой темы по нескольким критериям качества \cite{fan2019assessing}.

Таким образом, принятые методологии перекладывают ответственность за подбор гиперпараметров на исследователя; при этом процедура подбора остаётся нерегламентированной, что создаёт высокий барьер входа для не-специалистов. 
В обзорной монографии \cite{fntir2017applications} подчёркивается важность снижения порога входа и более жёсткой регламентации процесса построения моделей: <<первоочередная исследовательская задача в тематическом моделировании... сделать его более доступным>>.

Таким образом, важными нерешёнными проблемами являются: обеспечение  интерпретируемости моделей, подбор гиперпараметров и стандартизация процесса построения тематической модели для широкого класса пользовательских прикладных задач.

{\aim} данного диссертационного исследования является разработка и реализация технологии построения интерпретируемых аддитивно регуляризованных тематических моделей, применимой для решения широкого класса задач тематического моделирования. 

Для~достижения поставленной цели решаются следующие {\tasks}.
\begin{enumerate}[beginpenalty=10000] % https://tex.stackexchange.com/a/476052/104425
  \item Реализация, эмпирическое исследование и улучшение автоматически вычисляемых критериев интерпретируемости тематических моделей, в том числе новой разновидности критерия когерентности~--- внутритекстовой когерентности.
  \item Разработка методологии и средств автоматизации проведения экспериментов по подбору стратегии регуляризации и выбору гиперпараметров тематической модели.
  \item Проектирование архитектуры библиотеки TopicNet с открытым кодом на GitHub для реализации данной методологии. Разработка и реализация интерфейсов, обеспечивающих создание пользовательских регуляризаторов и метрик качества в TopicNet.
  \item Поиск универсального <<рецепта>> построения аддитивно регуляризованных тематических моделей, превосходящих LDA по совокупности критериев качества, применение которого не требовало бы от пользователя знания теории ARTM.
  \item Решение прикладных задач с использованием разработанной библиотеки TopicNet, в частности, задачи кластеризации интентов в текстовой коллекции обращений клиентов в контактный центр.
\end{enumerate}

{\novelty}
\begin{enumerate}[beginpenalty=10000] % https://tex.stackexchange.com/a/476052/104425
  \item Предложена методология многокритериального выбора моделей на основе <<кубов гиперпараметров>> в рамках теории аддитивной регуляризации тематических моделей (ARTM).
  \item Разработан универсальный <<рецепт>> построения аддитивно регуляризованных тематических моделей, превосходящих LDA по совокупности критериев качества.
  \item Предложена и реализована иерархическая тематическая модель с разными весами модальностей на разных уровнях иерархии. 
\end{enumerate}

\textbf{Теоретическая значимость.} 
Работа вносит вклад в развитие теории аддитивной регуляризации тематических моделей (ARTM), предоставляя исследователям удобную инструментальную среду для накопления эмпирических фактов о влиянии стратегии регуляризации на качество тематических моделей при многокритериальном оценивании. Вводятся понятия внутритекстовой когерентности, относительных и абсолютных коэффициентов регуляризации, фактора балансировки, дерева экспериментов, куба гиперпараметров, рецепта моделирования.

\textbf{Практическая значимость.} 
Предложенные подходы и методы реализованы в библиотеке тематического моделирования с открытым кодом TopicNet, которая может быть использована и уже используется для решения различных прикладных задач анализа текстовых и транзакционных данных. Реализованные в библиотеке концепции дерева экспериментов, куба гиперпараметров и рецепта моделирования позволяют находить, сохранять и распространять в сообществе исследователей удачные приёмы решения прикладных задач тематического моделирования.

Показано, что использование относительных коэффициентов регуляризации обеспечивает возможность переноса стратегии обучения тематической модели на другие текстовые коллекции: один и тот же набор значений относительных коэффициентов регуляризации и/или весов модальностей может быть использован для различных прикладных задач. В случае, когда непосредственный перенос численных значений нецелесообразен из-за специфики новой коллекции, относительные коэффициенты облегчают подбор оптимальных значений, поскольку они находятся в диапазоне $[0, 1]$ и интерпретируются как степень воздействия регуляризатора на модель по отношению к основному критерию логарифмированного правдоподобия.

Предложенные в данной работе и реализованные в TopicNet механизмы были успешно применены для решения ряда прикладных задач: 
задачи кластеризации интентов в текстовой коллекции обращений клиентов в контактный центр \cite{popov_hier}, 
задачи анализа банковских транзакционных данных \cite{egorov2019topic}, и других.

{\methods} В работе использованы методы теории вероятностей, численной оптимизации, автоматической обработки текстов, машинного обучения. Экспериментальное исследование проводится на языке Python; опубликованная на GitHub библиотека TopicNet, подытоживающая результаты исследования, открыта для свободного использования и удовлетворяет принципам воспроизводимости результатов.

{\defpositions}
\begin{enumerate}[beginpenalty=10000] % https://tex.stackexchange.com/a/476052/104425
  \item Изучение репрезентативности имеющихся мер интерпретируемости
  \item Предложены относительные веса модальностей, и относительные коэффициенты сглаживания/разреживания. Обеспечивают переносимость тематических моделей. Отличаются от аналогов...
  \item Псевдорегуляризатор, обеспечивающий быстрое однопроходное вычисление векторизации документов. Отличается от аналогов тем, что улучшает многие меры качества.
  \item Концепция дерева эксперимента и кубов в библиотеке TopicNet
  \item Новая адаптивная стратегия регуляризации, реализованная как отдельный куб в TopicNet
\end{enumerate}

{\reliability} полученных результатов обеспечивается вычислительными экспериментами на реальных текстовых коллекциях. Методика и результаты подробно описаны в тексте работы. Разработанный код библиотеки TopicNet и проведённых экспериментов находится в открытом доступе, что обеспечивает воспроизводимость результатов.  

{\probation}
Основные результаты диссертации докладывались на следующих конференциях и семинарах:
\begin{itemize}
    \item Международная конференция по компьютерной лингвистике <<Диалог>>, Москва, 1 июня 2018.
    \item International Conference Recent Advances in Natural Language Processing (RANLP), Варна, 3 сентября 2019.
    \item Открытая лекция в рамках образовательного проекта Физтех.Рост, Долгопрудный, 18 октября 2019.
    \item Выступление на открытом научном семинаре <<методы анализа текстов>>, Москва, 28 марта 2018.
    \item Презентация TopicNet на открытом научном семинаре, Москва, 10 августа 2019.
    \item Выступление на OpenTalks.AI~--- ведущей независимая открытая конференция по искусственному интеллекту, Москва, 20 февраля 2020 года.
    \item International Conference on Language Resources and Evaluation (LREC), Марсель (должна была состоятся в мае 2020).
\end{itemize}

{\contribution} Личный вклад диссертанта в работы, выполненные с
соавторами, заключается в следующем:
\begin{itemize}
    \item В работе \cite{intracoh} предложена идея генерации полусинтетической выборки, проведён эксперимент по подсчёту репрезентативности верхних токенов.
    \item В работе \cite{popov_hier} произведена интеграция алгоритма обучения в TopicNet; выдвинута идея разделения слов и нграмм по функциональному назначению; активное участие в анализе ошибок модели; применение относительных коэффициентов регуляризации,
    \item В работе \cite{bulatov2020topicnet} сформирована концепция разделения модулей Cooking Machine и Viewers, понятие куба и дерева эксперимента; написан список требований; реализован отбор моделей и связанный с ним domain-specific language; проведена часть экспериментов, связанная с GenSim и с различностью тем.
    \item В работе \cite{thetaless} произведена интеграция псевдорегуляризатора в TopicNet, проведена связанная с этим часть экспериментов.
\end{itemize}

\ifnumequal{\value{bibliosel}}{0}
{%%% Встроенная реализация с загрузкой файла через движок bibtex8. (При желании, внутри можно использовать обычные ссылки, наподобие `\cite{vakbib1,vakbib2}`).
    {\publications} Основные результаты по теме диссертации изложены
    в~XX~печатных изданиях,
    X из которых изданы в журналах, рекомендованных ВАК,
    X "--- в тезисах докладов.
}%
{%%% Реализация пакетом biblatex через движок biber
    \begin{refsection}[bl-author, bl-registered]
        % Это refsection=1.
        % Процитированные здесь работы:
        %  * подсчитываются, для автоматического составления фразы "Основные результаты ..."
        %  * попадают в авторскую библиографию, при usefootcite==0 и стиле `\insertbiblioauthor` или `\insertbiblioauthorgrouped`
        %  * нумеруются там в зависимости от порядка команд `\printbibliography` в этом разделе.
        %  * при использовании `\insertbiblioauthorgrouped`, порядок команд `\printbibliography` в нём должен быть тем же (см. biblio/biblatex.tex)
        %
        % Невидимый библиографический список для подсчёта количества публикаций:
        \ifxetexorluatex\selectlanguage{english}\fi
        \printbibliography[heading=nobibheading, section=1, env=countauthorvak,          keyword=biblioauthorvak]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorwos,          keyword=biblioauthorwos]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorscopus,       keyword=biblioauthorscopus]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorconf,         keyword=biblioauthorconf]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorother,        keyword=biblioauthorother]%
        \printbibliography[heading=nobibheading, section=1, env=countregistered,         keyword=biblioregistered]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorpatent,       keyword=biblioauthorpatent]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorprogram,      keyword=biblioauthorprogram]%
        \printbibliography[heading=nobibheading, section=1, env=countauthor,             keyword=biblioauthor]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorvakscopuswos, filter=vakscopuswos]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorscopuswos,    filter=scopuswos]%
        %
        \nocite{*}\ifxetexorluatex\selectlanguage{russian}\fi%
        %
        \nocite{intracoh, popov_hier, bulatov2020topicnet, thetaless, prog_cook, prog_view}
        
        {\publications} Основные результаты по теме диссертации изложены в~\arabic{citeauthor}~печатных изданиях,
        \arabic{citeauthorvak} из которых изданы в журналах, рекомендованных ВАК\sloppy%
        \ifnum \value{citeauthorscopuswos}>0%
            , \arabic{citeauthorscopuswos} "--- в~периодических научных журналах, индексируемых Web of~Science и Scopus\sloppy%
        \fi%
        \ifnum \value{citeauthorconf}>0%
            , \arabic{citeauthorconf} "--- в~тезисах докладов.
        \else%
            .
        \fi%
        \ifnum \value{citeregistered}=1%
            \ifnum \value{citeauthorpatent}=1%
                Зарегистрирован \arabic{citeauthorpatent} патент.
            \fi%
            \ifnum \value{citeauthorprogram}=1%
                Зарегистрирована \arabic{citeauthorprogram} программа для ЭВМ.
            \fi%
        \fi%
        \ifnum \value{citeregistered}>1%
            Зарегистрированы\ %
            \ifnum \value{citeauthorpatent}>0%
            \formbytotal{citeauthorpatent}{патент}{}{а}{}\sloppy%
            \ifnum \value{citeauthorprogram}=0 . \else \ и~\fi%
            \fi%
            \ifnum \value{citeauthorprogram}>0%
            \formbytotal{citeauthorprogram}{программ}{а}{ы}{} для ЭВМ.
            \fi%
        \fi%
        % К публикациям, в которых излагаются основные научные результаты диссертации на соискание учёной
        % степени, в рецензируемых изданиях приравниваются патенты на изобретения, патенты (свидетельства) на
        % полезную модель, патенты на промышленный образец, патенты на селекционные достижения, свидетельства
        % на программу для электронных вычислительных машин, базу данных, топологию интегральных микросхем,
        % зарегистрированные в установленном порядке.(в ред. Постановления Правительства РФ от 21.04.2016 N 335)
    \end{refsection}%
    \begin{refsection}[bl-author, bl-registered]
        % Это refsection=2.
        % Процитированные здесь работы:
        %  * попадают в авторскую библиографию, при usefootcite==0 и стиле `\insertbiblioauthorimportant`.
        %  * ни на что не влияют в противном случае
        \nocite{intracoh}
        \nocite{popov_hier}
        \nocite{bulatov2020topicnet}
        \nocite{thetaless}
        \nocite{prog_cook}
        \nocite{prog_view}
        
    \end{refsection}%
        %
        % Всё, что вне этих двух refsection, это refsection=0,
        %  * для диссертации - это нормальные ссылки, попадающие в обычную библиографию
        %  * для автореферата:
        %     * при usefootcite==0, ссылка корректно сработает только для источника из `external.bib`. Для своих работ --- напечатает "[0]" (и даже Warning не вылезет).
        %     * при usefootcite==1, ссылка сработает нормально. В авторской библиографии будут только процитированные в refsection=0 работы.
}


% Для добавления в список публикаций автора работ, которые не были процитированы в
% автореферате, требуется их~перечислить с использованием команды \verb!\nocite! в
% \verb!Synopsis/content.tex!.
